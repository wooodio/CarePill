import openai
import pyaudio
import wave
import threading
import time
import pygame
from io import BytesIO
import tempfile
import os
import json

class VoiceChatGPT:
    def __init__(self,config_path='config.json'):
        """
        OpenAI APIë¥¼ ì‚¬ìš©í•œ ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ
        
        Args:
            api_key (str): OpenAI API í‚¤
        """
        self.config = self.load_config(config_path)
        self.client = openai.OpenAI(api_key=self.config['openai_api_key'])
        self.is_recording = False
        self.audio_format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        self.chunk = 1024
        
        # PyAudio ì´ˆê¸°í™”
        self.audio = pyaudio.PyAudio()
        
        # Pygame mixer ì´ˆê¸°í™” (TTS ì¬ìƒìš©)
        pygame.mixer.init()
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        self.conversation_history = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”."}
        ]
    def load_config(self, config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            
            # í•„ìˆ˜ í‚¤ í™•ì¸
            required_keys = ['openai_api_key']  # API í‚¤ê°€ í•„ìˆ˜ í‚¤ë¡œ ì²´í¬ë¨
            for key in required_keys:
                if key not in config:
                    raise ValueError(f"ì„¤ì • íŒŒì¼ì— í•„ìˆ˜ í‚¤ '{key}'ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return config
    def record_audio(self, duration=5):
        """
        ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ ë…¹ìŒ
        
        Args:
            duration (int): ë…¹ìŒ ì‹œê°„ (ì´ˆ)
        
        Returns:
            str: ì„ì‹œ WAV íŒŒì¼ ê²½ë¡œ
        """
        print("ğŸ¤ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        stream = self.audio.open(
            format=self.audio_format,
            channels=self.channels,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunk
        )
        
        frames = []
        for _ in range(0, int(self.rate / self.chunk * duration)):
            data = stream.read(self.chunk)
            frames.append(data)
        
        stream.stop_stream()
        stream.close()
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        with wave.open(temp_file.name, 'wb') as wf:
            wf.setnchannels(self.channels)
            wf.setsampwidth(self.audio.get_sample_size(self.audio_format))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(frames))
        
        print("âœ… ë…¹ìŒ ì™„ë£Œ!")
        return temp_file.name
    
    def record_until_silence(self, silence_threshold=500, silence_duration=2):
        """
        ìŒì„±ì´ ëë‚  ë•Œê¹Œì§€ ë…¹ìŒ (ì¹¨ë¬µ ê°ì§€)
        
        Args:
            silence_threshold (int): ì¹¨ë¬µìœ¼ë¡œ ê°„ì£¼í•  ë³¼ë¥¨ ì„ê³„ê°’
            silence_duration (float): ì¹¨ë¬µì´ ì§€ì†ë˜ì–´ì•¼ í•˜ëŠ” ì‹œê°„ (ì´ˆ)
        """
        print("ğŸ¤ ë§ì”€í•˜ì„¸ìš”... (ì¹¨ë¬µì´ ê°ì§€ë˜ë©´ ìë™ìœ¼ë¡œ ì¢…ë£Œë©ë‹ˆë‹¤)")
        
        stream = self.audio.open(
            format=self.audio_format,
            channels=self.channels,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunk
        )
        
        frames = []
        silence_start = None
        
        while True:
            data = stream.read(self.chunk)
            frames.append(data)
            
            # ë³¼ë¥¨ ê³„ì‚°
            volume = max(data)
            
            if volume < silence_threshold:
                if silence_start is None:
                    silence_start = time.time()
                elif time.time() - silence_start > silence_duration:
                    print("ğŸ”‡ ì¹¨ë¬µ ê°ì§€ë¨. ë…¹ìŒì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
            else:
                silence_start = None
        
        stream.stop_stream()
        stream.close()
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        with wave.open(temp_file.name, 'wb') as wf:
            wf.setnchannels(self.channels)
            wf.setsampwidth(self.audio.get_sample_size(self.audio_format))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(frames))
        
        return temp_file.name
    
    def speech_to_text(self, audio_file_path):
        """
        Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            audio_file_path (str): ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        
        Returns:
            str: ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        print("ğŸ”„ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
        
        try:
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ko"  # í•œêµ­ì–´ ì§€ì •
                )
            
            text = transcript.text
            print(f"ğŸ‘¤ ì‚¬ìš©ì: {text}")
            return text
            
        except Exception as e:
            print(f"âŒ STT ì˜¤ë¥˜: {e}")
            return None
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(audio_file_path):
                os.unlink(audio_file_path)
    
    def chat_with_gpt(self, user_message):
        """
        ChatGPTì™€ ëŒ€í™”
        
        Args:
            user_message (str): ì‚¬ìš©ì ë©”ì‹œì§€
        
        Returns:
            str: GPT ì‘ë‹µ
        """
        print("ğŸ¤– ChatGPTê°€ ì‘ë‹µì„ ìƒì„± ì¤‘...")
        
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history.append({"role": "user", "content": user_message})
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",  # ë˜ëŠ” "gpt-4"
                messages=self.conversation_history,
                temperature=0.7,
                max_tokens=500
            )
            
            assistant_message = response.choices[0].message.content
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history.append({"role": "assistant", "content": assistant_message})
            
            print(f"ğŸ¤– ChatGPT: {assistant_message}")
            return assistant_message
            
        except Exception as e:
            print(f"âŒ ChatGPT API ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def text_to_speech(self, text):
        """
        OpenAI TTS APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒ
        
        Args:
            text (str): ë³€í™˜í•  í…ìŠ¤íŠ¸
        """
        print("ğŸ”Š ìŒì„±ì„ ìƒì„±í•˜ê³  ì¬ìƒ ì¤‘...")
        
        try:
            response = self.client.audio.speech.create(
                model=self.config['tts_model'],  # configì—ì„œ TTS ëª¨ë¸ ì‚¬ìš©
                voice=self.config['tts_voice'],   # configì—ì„œ ìŒì„± ì„¤ì • ì‚¬ìš©
                input=text
            )
            
            # BytesIOë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ
            audio_data = BytesIO(response.content)
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ì¬ìƒ
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as temp_file:
                temp_file.write(response.content)
                temp_file_path = temp_file.name
            
            # Pygameìœ¼ë¡œ ì¬ìƒ
            pygame.mixer.music.load(temp_file_path)
            pygame.mixer.music.play()
            
            # ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(temp_file_path)
            
        except Exception as e:
            print(f"âŒ TTS ì˜¤ë¥˜: {e}")
    
    def start_conversation(self):
        """
        ìŒì„± ëŒ€í™” ì‹œì‘
        """
        print("ğŸ‰ ChatGPT ìŒì„± ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!")
        print("ğŸ’¡ íŒ: 'exit', 'ì¢…ë£Œ', 'ë' ì´ë¼ê³  ë§í•˜ë©´ ëŒ€í™”ê°€ ì¢…ë£Œë©ë‹ˆë‹¤.")
        
        try:
            while True:
                print("\n" + "="*50)
                
                # 1. ìŒì„± ë…¹ìŒ
                audio_file = self.record_until_silence()
                
                # 2. STT (ìŒì„± â†’ í…ìŠ¤íŠ¸)
                user_text = self.speech_to_text(audio_file)
                
                if not user_text:
                    print("âŒ ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    continue
                
                # ì¢…ë£Œ í‚¤ì›Œë“œ í™•ì¸
                if any(keyword in user_text.lower() for keyword in ['exit', 'ì¢…ë£Œ', 'ë']):
                    print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                # 3. ChatGPTì™€ ëŒ€í™”
                gpt_response = self.chat_with_gpt(user_text)
                
                # 4. TTS (í…ìŠ¤íŠ¸ â†’ ìŒì„±)
                self.text_to_speech(gpt_response)
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ëŒ€í™”ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """
        ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        """
        self.audio.terminate()
        pygame.mixer.quit()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    try:
        # ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” (config.jsonì—ì„œ API í‚¤ ìë™ ë¡œë“œ)
        voice_chat = VoiceChatGPT()
        
        # ëŒ€í™” ì‹œì‘
        voice_chat.start_conversation()
        
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ”§ config.json íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")