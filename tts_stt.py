import os
import io
import time
import wave
import queue
import numpy as np
import sounddevice as sd
import soundfile as sf
import simpleaudio as sa
from pydub import AudioSegment
import requests
from openai import OpenAI


# ===== ì„¤ì • =====
SAMPLE_RATE = 16000
CHANNELS = 1
RECORD_SECONDS = 5         # Enter ëˆ„ë¥¼ ë•Œë§ˆë‹¤ ì´ ê¸¸ì´ë§Œí¼ ë…¹ìŒ
STT_MODEL = "gpt-4o-mini-transcribe"   # ê²½ëŸ‰/ì €ë¹„ìš© STT
CHAT_MODEL = "gpt-4o-mini"             # ë¹ ë¥´ê³  ì €ë ´í•œ ëŒ€í™” ëª¨ë¸
TTS_MODEL = "gpt-4o-mini-tts"          # ìì—°ìŠ¤ëŸ¬ìš´ TTS
TTS_VOICE = "alloy"                    # ìŒìƒ‰ ì´ë¦„(ë¬¸ì„œì— ì˜ˆì‹œ ì¡´ì¬)
API_KEY = os.environ.get("OPENAI_API_KEY")

client = OpenAI(api_key=API_KEY)

# ===== ìœ í‹¸: ë…¹ìŒ =====
def record_wav(temp_path="temp_input.wav", seconds=RECORD_SECONDS, sr=SAMPLE_RATE, ch=CHANNELS):
    print(f"\nğŸ™ï¸  {seconds}ì´ˆ ë…¹ìŒ ì‹œì‘... (ë§í•˜ì„¸ìš”)")
    audio = sd.rec(int(seconds * sr), samplerate=sr, channels=ch, dtype='float32')
    sd.wait()
    sf.write(temp_path, audio, sr)  # 16kHz mono WAV ì €ì¥
    print("âœ… ë…¹ìŒ ì™„ë£Œ.")
    return temp_path

# ===== ìœ í‹¸: STT(ìŒì„±â†’í…ìŠ¤íŠ¸) =====
def transcribe_wav(path):
    # RESTë¡œ í˜¸ì¶œ(ë¯¿ìŒì§), ê³µì‹ ì—”ë“œí¬ì¸íŠ¸: /v1/audio/transcriptions
    # ì°¸ê³ : Speech-to-Text ê°€ì´ë“œ & API ë ˆí¼ëŸ°ìŠ¤. :contentReference[oaicite:2]{index=2}
    url = "https://api.openai.com/v1/audio/transcriptions"
    headers = {"Authorization": f"Bearer {API_KEY}"}
    with open(path, "rb") as f:
        files = {"file": (os.path.basename(path), f, "audio/wav")}
        data = {"model": STT_MODEL, "response_format": "json"}  # í•œêµ­ì–´ ìë™ ì¸ì‹
        resp = requests.post(url, headers=headers, files=files, data=data, timeout=120)
    resp.raise_for_status()
    text = resp.json().get("text", "").strip()
    return text

# ===== ìœ í‹¸: Chat (í…ìŠ¤íŠ¸â†’í…ìŠ¤íŠ¸) =====
def chat_reply(messages):
    # Chat Completions(ë˜ëŠ” Responses)ë¡œ ëŒ€í™”
    # ì—¬ê¸°ì„  ì¹œìˆ™í•œ Chat Completions ì‚¬ìš©
    resp = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=messages,
        temperature=0.7
    )
    return resp.choices[0].message.content.strip()

def tts_speak(text, fmt="wav"):
    """
    - OpenAI TTSë¥¼ 'wav'ë¡œ ë°›ì•„ ë°”ë¡œ ì¬ìƒ
    - fmt="wav" ê¶Œì¥ (mp3ëŠ” ffmpeg í•„ìš”)
    """
    url = "https://api.openai.com/v1/audio/speech"
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "gpt-4o-mini-tts",
        "voice": "alloy",
        "input": text,
        "format": fmt  # "wav" ê¶Œì¥
    }
    r = requests.post(url, headers=headers, json=payload, timeout=120)
    r.raise_for_status()
    audio_bytes = io.BytesIO(r.content)

    if fmt == "wav":
        # ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ ë¡œë“œ & ì¬ìƒ
        data, sr = sf.read(audio_bytes, dtype="float32")
        sd.play(data, sr)
        sd.wait()
    else:
        # mp3 ë“±ì€ ffmpegê°€ í•„ìš”í•©ë‹ˆë‹¤. ê°€ê¸‰ì  fmt="wav" ì‚¬ìš© ê¶Œì¥
        raise RuntimeError("fmt='wav'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (mp3 ì¬ìƒì€ ffmpeg í•„ìš”).")

def main():
    print("ìŒì„± ëŒ€í™” ë°ëª¨ ì‹œì‘.")
    print("Enter í‚¤ë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒí•˜ê³ , 'q' ì…ë ¥ ì‹œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ëŠ” ìŒì„± ë¹„ì„œì…ë‹ˆë‹¤."}
    ]

    while True:
        cmd = input("\n[Enter=ë…¹ìŒ / q=ì¢…ë£Œ] > ").strip().lower()
        if cmd == "q":
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        wav_path = record_wav()
        try:
            user_text = transcribe_wav(wav_path)
        except Exception as e:
            print(f"STT ì˜¤ë¥˜: {e}")
            continue

        if not user_text:
            print("ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        print(f"ğŸ‘¤ ì‚¬ìš©ì: {user_text}")
        messages.append({"role": "user", "content": user_text})

        try:
            assistant_text = chat_reply(messages)
        except Exception as e:
            print(f"Chat ì˜¤ë¥˜: {e}")
            continue

        print(f"ğŸ¤– ì–´ì‹œìŠ¤í„´íŠ¸: {assistant_text}")
        messages.append({"role": "assistant", "content": assistant_text})

        try:
            tts_speak(assistant_text, fmt="mp3")
        except Exception as e:
            print(f"TTS ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    if not API_KEY:
        raise RuntimeError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    main()